% !TeX spellcheck = en_US
\chapter{Testing}
\section*{Languages and Frameworks}
In order to test our system, we need to use a tool to create a \textit{virtual network} inside our machine: we used \texttt{mininet}\footnote{http://mininet.org/}, 
exploiting the \texttt{python2} APIs. To simulate input from an external application we also used a python2 library, called \texttt{requests}\footnote{https://docs.python-requests.org/en/latest/},
which is able to act like an HTTP client.\
Given that our developement environment is inside a virtual machine, we will keep the number of virtual devices relatively small, in order to not
overload the VM resources.

\section*{Scenario}
We want to simulate a typical data center scenario with a single LAN, implemented in a \textit{Spine-Leaf} topology. This configuration
is widely used thanks to its easy scalability and sufficient redundancy.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.90\textwidth]{img/spine_leaf.pdf}
    \caption{example of \textit{spine-leaf} topology}
\end{figure}

\section{Link Failure Test}
\noindent Using \texttt{mininet}, we can also simulate an episode of link failure, in order to test the system behaviour in this specific case. The system is able to recompute a functional path between two host and use it to forward packets.

\noindent In order to perform this test we use a spine leaf network with 2 spines and 3 leaf, each leaf has two hosts connected to it. The links of the network can be seen in figure \ref{img:links}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.50\textwidth]{img/links.png}
	\caption{Links of the spine leaf network}
	\label{img:links}
\end{figure}

\noindent To prove that the system is capable of handling a link failure we will establish an intent, use wireshark to sniff the traffic on the interfaces of the spines and see what happens when a link failure takes place and how the traffic is redirected.

\noindent The first thing to do is obviously to start the floodlight controller and the network\footnote{through the script scripts/start\_only\_spine\_topo.py}, then we establish an intent between the host11 (connected to leaf21) and the host21 (connected to leaf22). In order to check the connectivity we use wireshark on spine11-eth1 (the interface that connects leaf21 with spine11) and spine12-eth1 (the interface that connects leaf21 with spine12) and we perform a ping between the two hosts to see what happens on these interfaces.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{img/test1.png}
\caption{Ping between host11 and host21}
\label{img:ping1}
\end{figure}

\noindent As we can see in figure \ref{img:ping1} the ping is executed successfully and both interfaces are used, one for sending packets from h11 to h21 and the other for the reverse path.

\noindent Now we put down the link between leaf21 and spine11, so the interface spine11-eth1 goes down (see figure \ref{img:linkdown}). Nevertheless we can see that the ping continues to be performed successfully because now only the interface spine12-eth1 is used for both the direct and the reverse path (figure \ref{img:linkdown}).

\noindent The only indication that a link failure has took place is the fact that one ping needs more time to be completed (see figure \ref{img:ping_detail}) because of the overhead caused by the reconfiguration of the path, but the connectivity is ensured in any case (in fact in figure \ref{img:ping_detail} we can see that no icmp packets have been lost because there is no gap in icmp\_seq) and the delay affects only one packet. Hence at the end we can say that the intent continues to work even if a link fails, thus the system is able to cope with a link failure.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{img/test2.png}
	\caption{We put down the link between leaf21 and spine11 but the ping continues to work.}
	\label{img:linkdown}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{img/ping_detail.png}
	\caption{}
	\label{img:ping_detail}
\end{figure}


\newpage

\section{Ping Latency}
In order to measure the network performance we will consider a fixed scenario with 2 spines, 3 leafs and 4 hosts for each leafs (i.e. 12 hosts in total);
for every host:
\begin{itemize}
    \item  we establish an intent with another random chosen one;
    \item  we start a ping session, measuring the \texttt{round trip time} of each packet
    \item  the session end when 10 ping are successfully exchanged, or the last timeout elapses
\end{itemize} 
\begin{figure}[h]
    \centering
    \includegraphics[width=.92\textwidth]{img/mean_ping_time.pdf}
    \caption{Ping times with 12 hosts}
    \label{img:perf1}
\end{figure}
First of all we monitor the number of \texttt{DESTINATION HOST UNREACHABLE} and \texttt{DUPLICATE}, those 2 parameters are equal to 0, confirming the correct
behaviour of the network.
The performance results (see figure \ref{img:perf1}) are consistent with our expectation:
\begin{itemize}
    \item the first ping is significantly slower than the others, because it is processed by the controller, triggering the route establishment;
    \item subsequent pings are very fast (<1 ms), because they don't have to traverse "real" network cables and because they are processed by the virtual switches and not by the controller.
\end{itemize}
\newpage
\begin{figure}[h]
    \centering
    \includegraphics[width=.94\textwidth]{img/increasing_ping_time.pdf}
    \caption{Ping times with different loads}
    \label{img:perf2}
\end{figure}
\noindent We also tried to evaluate the elasticity of the network with increasing load of traffic (i.e. increasing number of host pinging at the same time) and the results of this tests can be seen in figure \ref{img:perf2}.\\
The time needed for the first ping to complete tends to increase with the amount of traffic meanwhile the time for the others pings remains pretty stable
(mind the confidence intervals). This is expected because route establishment is done by the controller in a centralized way (the requests will queue up);
once the route is established, switches will handle the traffic in a distributed manner, leading to optimal forwarding of traffic.